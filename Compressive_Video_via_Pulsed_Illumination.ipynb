{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FOGuzman/PulseIlluminationVideo/blob/main/Compressive_Video_via_Pulsed_Illumination.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "KeMRObsvWytF"
      },
      "source": [
        "# Compressive video via Pulsed Illumination"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "foxXY7mKFl5i"
      },
      "source": [
        "## Setup\n",
        "\n",
        "*   Preparing repository\n",
        "*   Download DAVIS2017 dataset\n",
        "*   Install extra dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tql7UXtuiyAn",
        "outputId": "3193b09a-01e4-4b53-b10f-e87f9d9924da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'PulseIlluminationVideo'...\n",
            "remote: Enumerating objects: 429, done.\u001b[K\n",
            "remote: Total 429 (delta 0), reused 0 (delta 0), pack-reused 429\u001b[K\n",
            "Receiving objects: 100% (429/429), 77.38 MiB | 25.85 MiB/s, done.\n",
            "Resolving deltas: 100% (203/203), done.\n",
            "/content/PulseIlluminationVideo\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/FOGuzman/PulseIlluminationVideo.git\n",
        "%cd PulseIlluminationVideo/\n",
        "!wget https://data.vision.ee.ethz.ch/csergi/share/davis/DAVIS-2017-trainval-480p.zip\n",
        "!mkdir -p ./dataset/\n",
        "!unzip DAVIS-2017-trainval-480p.zip -d ./dataset/\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "LSFoaQElkbcW"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHC9wZKhkDK5",
        "outputId": "40f83c65-c2f7-4a1b-d43e-9aee3f4bdc89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'PulseIlluminationVideo/'\n",
            "/content/PulseIlluminationVideo\n"
          ]
        }
      ],
      "source": [
        "from unet import UNet\n",
        "from inverse import  StandardConv2D\n",
        "import os\n",
        "import os.path as osp\n",
        "import sys \n",
        "BASE_DIR = osp.dirname(osp.dirname(osp.abspath(\"__file__\")))\n",
        "sys.path.append(BASE_DIR)\n",
        "import utils\n",
        "from cacti.datasets.builder import build_dataset \n",
        "from cacti.models.builder import build_model\n",
        "from cacti.utils.optim_builder import  build_optimizer\n",
        "from cacti.utils.loss_builder import build_loss\n",
        "from torch.utils.data import DataLoader\n",
        "from cacti.utils.mask import generate_masks\n",
        "from cacti.utils.config import Config\n",
        "from cacti.utils.logger import Logger\n",
        "from cacti.utils.utils import save_image, load_checkpoints, get_device_info\n",
        "from cacti.utils.eval_coarse import eval_psnr_ssim\n",
        "import torch\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import torch.distributed as dist\n",
        "from torch.utils.data.distributed import DistributedSampler\n",
        "from torch.nn.parallel import DistributedDataParallel as DDP\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "import time\n",
        "import argparse \n",
        "import json \n",
        "import einops"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "AWemheEUGAqQ"
      },
      "source": [
        "## Train initblock (Unet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gmjG6ImhldWz",
        "outputId": "3f532d5d-fdeb-48d1-843c-4315eb84a091"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:root:GPU info:\n",
            "--------------------------------------------------------------------------------\n",
            "CUDA available: True\n",
            "GPU numbers: 1\n",
            "GPU INFO: [{'GPU 0': 'Tesla T4'}]\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "2023-05-20 03:12:47,707 - <ipython-input-5-1c8d53db53e1> [line: 79] - GPU info:\n",
            "--------------------------------------------------------------------------------\n",
            "CUDA available: True\n",
            "GPU numbers: 1\n",
            "GPU INFO: [{'GPU 0': 'Tesla T4'}]\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "INFO:root:cfg info:\n",
            "--------------------------------------------------------------------------------\n",
            "{\n",
            "    \"test_data\": {\n",
            "        \"type\": \"SixGraySimData\",\n",
            "        \"data_root\": \"test_datasets/simulation\",\n",
            "        \"mask_path\": \"test_datasets/mask/shutter_mask16.mat\",\n",
            "        \"mask_shape\": null\n",
            "    },\n",
            "    \"resize_h\": 256,\n",
            "    \"resize_w\": 256,\n",
            "    \"train_pipeline\": [\n",
            "        {\n",
            "            \"type\": \"RandomResize\"\n",
            "        },\n",
            "        {\n",
            "            \"type\": \"RandomCrop\",\n",
            "            \"crop_h\": 128,\n",
            "            \"crop_w\": 128,\n",
            "            \"random_size\": true\n",
            "        },\n",
            "        {\n",
            "            \"type\": \"Flip\",\n",
            "            \"direction\": \"horizontal\",\n",
            "            \"flip_ratio\": 0.5\n",
            "        },\n",
            "        {\n",
            "            \"type\": \"Flip\",\n",
            "            \"direction\": \"diagonal\",\n",
            "            \"flip_ratio\": 0.5\n",
            "        },\n",
            "        {\n",
            "            \"type\": \"Resize\",\n",
            "            \"resize_h\": 256,\n",
            "            \"resize_w\": 256\n",
            "        }\n",
            "    ],\n",
            "    \"gene_meas\": {\n",
            "        \"type\": \"GenerationGrayMeas\"\n",
            "    },\n",
            "    \"train_data\": {\n",
            "        \"type\": \"DavisData\",\n",
            "        \"data_root\": \"./dataset/DAVIS/JPEGImages/480p/\",\n",
            "        \"mask_path\": \"test_datasets/mask/shutter_mask16.mat\",\n",
            "        \"pipeline\": [\n",
            "            {\n",
            "                \"type\": \"RandomResize\"\n",
            "            },\n",
            "            {\n",
            "                \"type\": \"RandomCrop\",\n",
            "                \"crop_h\": 128,\n",
            "                \"crop_w\": 128,\n",
            "                \"random_size\": true\n",
            "            },\n",
            "            {\n",
            "                \"type\": \"Flip\",\n",
            "                \"direction\": \"horizontal\",\n",
            "                \"flip_ratio\": 0.5\n",
            "            },\n",
            "            {\n",
            "                \"type\": \"Flip\",\n",
            "                \"direction\": \"diagonal\",\n",
            "                \"flip_ratio\": 0.5\n",
            "            },\n",
            "            {\n",
            "                \"type\": \"Resize\",\n",
            "                \"resize_h\": 256,\n",
            "                \"resize_w\": 256\n",
            "            }\n",
            "        ],\n",
            "        \"gene_meas\": {\n",
            "            \"type\": \"GenerationGrayMeas\"\n",
            "        },\n",
            "        \"mask_shape\": [\n",
            "            256,\n",
            "            256,\n",
            "            16\n",
            "        ]\n",
            "    },\n",
            "    \"checkpoint_config\": {\n",
            "        \"interval\": 2\n",
            "    },\n",
            "    \"log_config\": {\n",
            "        \"interval\": 100\n",
            "    },\n",
            "    \"save_image_config\": {\n",
            "        \"interval\": 500\n",
            "    },\n",
            "    \"optimizer\": {\n",
            "        \"type\": \"Adam\",\n",
            "        \"lr\": 0.0001\n",
            "    },\n",
            "    \"loss\": {\n",
            "        \"type\": \"MSELoss\"\n",
            "    },\n",
            "    \"runner\": {\n",
            "        \"max_epochs\": 400,\n",
            "        \"max_epoch\": 400\n",
            "    },\n",
            "    \"checkpoints\": null,\n",
            "    \"resume\": null,\n",
            "    \"data\": {\n",
            "        \"samples_per_gpu\": 18,\n",
            "        \"workers_per_gpu\": 4\n",
            "    },\n",
            "    \"crop_h\": 128,\n",
            "    \"crop_w\": 128,\n",
            "    \"model\": {\n",
            "        \"type\": \"STFormer\",\n",
            "        \"color_channels\": 1,\n",
            "        \"units\": 2,\n",
            "        \"dim\": 32,\n",
            "        \"frames\": 16\n",
            "    },\n",
            "    \"eval\": {\n",
            "        \"flag\": true,\n",
            "        \"interval\": 1\n",
            "    }\n",
            "}\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "2023-05-20 03:12:47,713 - <ipython-input-5-1c8d53db53e1> [line: 83] - cfg info:\n",
            "--------------------------------------------------------------------------------\n",
            "{\n",
            "    \"test_data\": {\n",
            "        \"type\": \"SixGraySimData\",\n",
            "        \"data_root\": \"test_datasets/simulation\",\n",
            "        \"mask_path\": \"test_datasets/mask/shutter_mask16.mat\",\n",
            "        \"mask_shape\": null\n",
            "    },\n",
            "    \"resize_h\": 256,\n",
            "    \"resize_w\": 256,\n",
            "    \"train_pipeline\": [\n",
            "        {\n",
            "            \"type\": \"RandomResize\"\n",
            "        },\n",
            "        {\n",
            "            \"type\": \"RandomCrop\",\n",
            "            \"crop_h\": 128,\n",
            "            \"crop_w\": 128,\n",
            "            \"random_size\": true\n",
            "        },\n",
            "        {\n",
            "            \"type\": \"Flip\",\n",
            "            \"direction\": \"horizontal\",\n",
            "            \"flip_ratio\": 0.5\n",
            "        },\n",
            "        {\n",
            "            \"type\": \"Flip\",\n",
            "            \"direction\": \"diagonal\",\n",
            "            \"flip_ratio\": 0.5\n",
            "        },\n",
            "        {\n",
            "            \"type\": \"Resize\",\n",
            "            \"resize_h\": 256,\n",
            "            \"resize_w\": 256\n",
            "        }\n",
            "    ],\n",
            "    \"gene_meas\": {\n",
            "        \"type\": \"GenerationGrayMeas\"\n",
            "    },\n",
            "    \"train_data\": {\n",
            "        \"type\": \"DavisData\",\n",
            "        \"data_root\": \"./dataset/DAVIS/JPEGImages/480p/\",\n",
            "        \"mask_path\": \"test_datasets/mask/shutter_mask16.mat\",\n",
            "        \"pipeline\": [\n",
            "            {\n",
            "                \"type\": \"RandomResize\"\n",
            "            },\n",
            "            {\n",
            "                \"type\": \"RandomCrop\",\n",
            "                \"crop_h\": 128,\n",
            "                \"crop_w\": 128,\n",
            "                \"random_size\": true\n",
            "            },\n",
            "            {\n",
            "                \"type\": \"Flip\",\n",
            "                \"direction\": \"horizontal\",\n",
            "                \"flip_ratio\": 0.5\n",
            "            },\n",
            "            {\n",
            "                \"type\": \"Flip\",\n",
            "                \"direction\": \"diagonal\",\n",
            "                \"flip_ratio\": 0.5\n",
            "            },\n",
            "            {\n",
            "                \"type\": \"Resize\",\n",
            "                \"resize_h\": 256,\n",
            "                \"resize_w\": 256\n",
            "            }\n",
            "        ],\n",
            "        \"gene_meas\": {\n",
            "            \"type\": \"GenerationGrayMeas\"\n",
            "        },\n",
            "        \"mask_shape\": [\n",
            "            256,\n",
            "            256,\n",
            "            16\n",
            "        ]\n",
            "    },\n",
            "    \"checkpoint_config\": {\n",
            "        \"interval\": 2\n",
            "    },\n",
            "    \"log_config\": {\n",
            "        \"interval\": 100\n",
            "    },\n",
            "    \"save_image_config\": {\n",
            "        \"interval\": 500\n",
            "    },\n",
            "    \"optimizer\": {\n",
            "        \"type\": \"Adam\",\n",
            "        \"lr\": 0.0001\n",
            "    },\n",
            "    \"loss\": {\n",
            "        \"type\": \"MSELoss\"\n",
            "    },\n",
            "    \"runner\": {\n",
            "        \"max_epochs\": 400,\n",
            "        \"max_epoch\": 400\n",
            "    },\n",
            "    \"checkpoints\": null,\n",
            "    \"resume\": null,\n",
            "    \"data\": {\n",
            "        \"samples_per_gpu\": 18,\n",
            "        \"workers_per_gpu\": 4\n",
            "    },\n",
            "    \"crop_h\": 128,\n",
            "    \"crop_w\": 128,\n",
            "    \"model\": {\n",
            "        \"type\": \"STFormer\",\n",
            "        \"color_channels\": 1,\n",
            "        \"units\": 2,\n",
            "        \"dim\": 32,\n",
            "        \"frames\": 16\n",
            "    },\n",
            "    \"eval\": {\n",
            "        \"flag\": true,\n",
            "        \"interval\": 1\n",
            "    }\n",
            "}\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "INFO:root:Model info:\n",
            "--------------------------------------------------------------------------------\n",
            "UNet(\n",
            "  (invNet): StandardConv2D(\n",
            "    (inverse_layer): Sequential(\n",
            "      (0): Conv2d(3, 16, kernel_size=(27, 27), stride=(1, 1), padding=(13, 13))\n",
            "      (1): LeakyReLU(negative_slope=0.01)\n",
            "    )\n",
            "    (inverse_layer2): Sequential(\n",
            "      (0): Conv2d(16, 16, kernel_size=(27, 27), stride=(1, 1), padding=(13, 13))\n",
            "      (1): LeakyReLU(negative_slope=0.01)\n",
            "    )\n",
            "  )\n",
            "  (conv_encode1): Sequential(\n",
            "    (0): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU()\n",
            "  )\n",
            "  (conv_maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv_encode2): Sequential(\n",
            "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU()\n",
            "  )\n",
            "  (conv_maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv_encode3): Sequential(\n",
            "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU()\n",
            "  )\n",
            "  (conv_maxpool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (bottleneck): Sequential(\n",
            "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU()\n",
            "    (4): Upsample(scale_factor=2.0, mode='nearest')\n",
            "    (5): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  )\n",
            "  (conv_decode3): Sequential(\n",
            "    (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU()\n",
            "    (4): Upsample(scale_factor=2.0, mode='nearest')\n",
            "    (5): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  )\n",
            "  (conv_decode2): Sequential(\n",
            "    (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU()\n",
            "    (4): Upsample(scale_factor=2.0, mode='nearest')\n",
            "    (5): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  )\n",
            "  (final_layer): Sequential(\n",
            "    (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU()\n",
            "    (4): Conv2d(64, 14, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            ")\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "2023-05-20 03:12:47,719 - <ipython-input-5-1c8d53db53e1> [line: 87] - Model info:\n",
            "--------------------------------------------------------------------------------\n",
            "UNet(\n",
            "  (invNet): StandardConv2D(\n",
            "    (inverse_layer): Sequential(\n",
            "      (0): Conv2d(3, 16, kernel_size=(27, 27), stride=(1, 1), padding=(13, 13))\n",
            "      (1): LeakyReLU(negative_slope=0.01)\n",
            "    )\n",
            "    (inverse_layer2): Sequential(\n",
            "      (0): Conv2d(16, 16, kernel_size=(27, 27), stride=(1, 1), padding=(13, 13))\n",
            "      (1): LeakyReLU(negative_slope=0.01)\n",
            "    )\n",
            "  )\n",
            "  (conv_encode1): Sequential(\n",
            "    (0): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU()\n",
            "  )\n",
            "  (conv_maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv_encode2): Sequential(\n",
            "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU()\n",
            "  )\n",
            "  (conv_maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv_encode3): Sequential(\n",
            "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU()\n",
            "  )\n",
            "  (conv_maxpool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (bottleneck): Sequential(\n",
            "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU()\n",
            "    (4): Upsample(scale_factor=2.0, mode='nearest')\n",
            "    (5): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  )\n",
            "  (conv_decode3): Sequential(\n",
            "    (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU()\n",
            "    (4): Upsample(scale_factor=2.0, mode='nearest')\n",
            "    (5): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  )\n",
            "  (conv_decode2): Sequential(\n",
            "    (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU()\n",
            "    (4): Upsample(scale_factor=2.0, mode='nearest')\n",
            "    (5): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  )\n",
            "  (final_layer): Sequential(\n",
            "    (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU()\n",
            "    (4): Conv2d(64, 14, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            ")\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "INFO:root:No pre_train model\n",
            "2023-05-20 03:12:47,946 - <ipython-input-5-1c8d53db53e1> [line: 129] - No pre_train model\n",
            "INFO:root:epoch: [0][  0/638], lr: 0.000100, loss: 0.42546.\n",
            "2023-05-20 03:13:06,514 - <ipython-input-5-1c8d53db53e1> [line: 186] - epoch: [0][  0/638], lr: 0.000100, loss: 0.42546.\n",
            "INFO:root:epoch: [0][100/638], lr: 0.000100, loss: 0.09281.\n",
            "2023-05-20 03:19:21,862 - <ipython-input-5-1c8d53db53e1> [line: 186] - epoch: [0][100/638], lr: 0.000100, loss: 0.09281.\n",
            "INFO:root:epoch: [0][200/638], lr: 0.000100, loss: 0.08654.\n",
            "2023-05-20 03:25:36,834 - <ipython-input-5-1c8d53db53e1> [line: 186] - epoch: [0][200/638], lr: 0.000100, loss: 0.08654.\n",
            "INFO:root:epoch: [0][300/638], lr: 0.000100, loss: 0.08861.\n",
            "2023-05-20 03:31:51,600 - <ipython-input-5-1c8d53db53e1> [line: 186] - epoch: [0][300/638], lr: 0.000100, loss: 0.08861.\n",
            "INFO:root:epoch: [0][400/638], lr: 0.000100, loss: 0.07905.\n",
            "2023-05-20 03:38:06,910 - <ipython-input-5-1c8d53db53e1> [line: 186] - epoch: [0][400/638], lr: 0.000100, loss: 0.07905.\n",
            "INFO:root:epoch: [0][500/638], lr: 0.000100, loss: 0.08348.\n",
            "2023-05-20 03:44:22,020 - <ipython-input-5-1c8d53db53e1> [line: 186] - epoch: [0][500/638], lr: 0.000100, loss: 0.08348.\n",
            "INFO:root:epoch: [0][600/638], lr: 0.000100, loss: 0.06178.\n",
            "2023-05-20 03:50:38,766 - <ipython-input-5-1c8d53db53e1> [line: 186] - epoch: [0][600/638], lr: 0.000100, loss: 0.06178.\n",
            "INFO:root:epoch: 0, avg_loss: 0.08842, time: 2408.78s.\n",
            "\n",
            "2023-05-20 03:52:56,731 - <ipython-input-5-1c8d53db53e1> [line: 196] - epoch: 0, avg_loss: 0.08842, time: 2408.78s.\n",
            "\n",
            "INFO:root:Mean PSNR: \n",
            "kobe16p1: 37.6005, traffic16p1: 37.6005, traffic16p2: 27.2183, crash16p1: 31.9451, kobe16p2: 36.7321, aerial16p2: 31.4518, crash16p2: 30.5779, aerial16p1: 31.7778, psnr_mean: 33.1130.\n",
            "\n",
            "2023-05-20 03:53:01,580 - <ipython-input-5-1c8d53db53e1> [line: 218] - Mean PSNR: \n",
            "kobe16p1: 37.6005, traffic16p1: 37.6005, traffic16p2: 27.2183, crash16p1: 31.9451, kobe16p2: 36.7321, aerial16p2: 31.4518, crash16p2: 30.5779, aerial16p1: 31.7778, psnr_mean: 33.1130.\n",
            "\n",
            "INFO:root:Mean SSIM: \n",
            "kobe16p1: 0.6082, traffic16p1: 0.6082, traffic16p2: 0.4643, crash16p1: 0.7416, kobe16p2: 0.5697, aerial16p2: 0.7210, crash16p2: 0.6967, aerial16p1: 0.7079, ssim_mean: 0.6397.\n",
            "\n",
            "2023-05-20 03:53:01,584 - <ipython-input-5-1c8d53db53e1> [line: 219] - Mean SSIM: \n",
            "kobe16p1: 0.6082, traffic16p1: 0.6082, traffic16p2: 0.4643, crash16p1: 0.7416, kobe16p2: 0.5697, aerial16p2: 0.7210, crash16p2: 0.6967, aerial16p1: 0.7079, ssim_mean: 0.6397.\n",
            "\n",
            "INFO:root:epoch: [1][  0/638], lr: 0.000100, loss: 0.07480.\n",
            "2023-05-20 03:53:12,821 - <ipython-input-5-1c8d53db53e1> [line: 186] - epoch: [1][  0/638], lr: 0.000100, loss: 0.07480.\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-1c8d53db53e1>\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "parser = argparse.ArgumentParser() \n",
        "args = parser.parse_args(args=[])\n",
        "args.config = './configs/STFormer/stformer_base.py'\n",
        "args.work_dir = './train_results/3meas_coarse_nm/'\n",
        "args.dataset_path = './dataset/DAVIS/JPEGImages/480p/'\n",
        "args.device = \"cuda\"\n",
        "args.resolution = [256,256]\n",
        "args.frames = 16\n",
        "args.dataset_crop = [128,128]\n",
        "args.distributed = False\n",
        "args.resume = None\n",
        "args.Epochs = 400\n",
        "args.batch_size = 18\n",
        "args.learning_rate = 0.0001\n",
        "args.saveImageEach = 500\n",
        "args.saveModelEach = 2\n",
        "args.checkpoints = None\n",
        "args.local_rank = -1\n",
        "args.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "if os.path.exists('/content/gdrive'):\n",
        "    print(\"GDrive Mounted, saving results on MyDrive/PulsedIlluminationRepository/results/\")\n",
        "    args.gdrivepath = \"/content/gdrive/MyDrive/PulsedIlluminationRepository/results/\"\n",
        "    if os.path.exists(args.gdrivepath):\n",
        "      os.makedirs(args.gdrivepath)\n",
        "      gdFlag = True\n",
        "else:\n",
        "  gdFlag = False  \n",
        "\n",
        "if __name__ == '__main__':\n",
        "    cfg = Config.fromfile(args.config)\n",
        "    cfg.resize_h,cfg.resize_w = args.resolution\n",
        "    cfg.crop_h,cfg.crop_w = args.dataset_crop\n",
        "    \n",
        "    cfg.train_pipeline[4]['resize_h'],cfg.train_pipeline[4]['resize_w'] = args.resolution\n",
        "    cfg.train_pipeline[1]['crop_h'],cfg.train_pipeline[1]['crop_w'] = args.dataset_crop\n",
        "    cfg.train_data.mask_shape = (args.resolution[0],args.resolution[1],args.frames)\n",
        "    \n",
        "\n",
        "    cfg.save_image_config['interval'] = args.saveImageEach\n",
        "    cfg.runner['max_epoch'] = args.Epochs\n",
        "    cfg.optimizer['lr'] = args.learning_rate\n",
        "    cfg.data['samples_per_gpu'] = args.batch_size\n",
        "    cfg.train_data['data_root'] = args.dataset_path\n",
        "    cfg.checkpoints = args.checkpoints\n",
        "    cfg.checkpoint_config['interval'] = args.saveModelEach\n",
        "    \n",
        "    if args.work_dir is None:\n",
        "        args.work_dir = osp.join('./work_dirs',osp.splitext(osp.basename(args.config))[0])\n",
        "\n",
        "    if args.resume is not None:\n",
        "        cfg.resume = args.resume\n",
        "\n",
        "    log_dir = osp.join(args.work_dir,\"log\")\n",
        "    show_dir = osp.join(args.work_dir,\"show\")\n",
        "    train_image_save_dir = osp.join(args.work_dir,\"train_images\")\n",
        "    checkpoints_dir = osp.join(args.work_dir,\"checkpoints\")\n",
        "\n",
        "    if not osp.exists(log_dir):\n",
        "        os.makedirs(log_dir)\n",
        "    if not osp.exists(show_dir):\n",
        "        os.makedirs(show_dir)\n",
        "    if not osp.exists(train_image_save_dir):\n",
        "        os.makedirs(train_image_save_dir)\n",
        "    if not osp.exists(checkpoints_dir):\n",
        "        os.makedirs(checkpoints_dir)\n",
        "\n",
        "    logger = Logger(log_dir)\n",
        "    writer = SummaryWriter(log_dir = show_dir)\n",
        "\n",
        "    rank = 0 \n",
        "    if args.distributed:\n",
        "        local_rank = int(args.local_rank)\n",
        "        dist.init_process_group(backend=\"nccl\")\n",
        "        rank = dist.get_rank()\n",
        "\n",
        "    dash_line = '-' * 80 + '\\n'\n",
        "    device_info = get_device_info()\n",
        "    env_info = '\\n'.join(['{}: {}'.format(k,v) for k, v in device_info.items()])\n",
        "\n",
        "    device = args.device\n",
        "    model = UNet(in_channel=16, out_channel=14, instance_norm=False).cuda()\n",
        "\n",
        "\n",
        "    if rank==0:\n",
        "        logger.info('GPU info:\\n' \n",
        "                + dash_line + \n",
        "                env_info + '\\n' +\n",
        "                dash_line)\n",
        "        logger.info('cfg info:\\n'\n",
        "                + dash_line + \n",
        "                json.dumps(cfg, indent=4)+'\\n'+\n",
        "                dash_line) \n",
        "        logger.info('Model info:\\n'\n",
        "                + dash_line + \n",
        "                str(model)+'\\n'+\n",
        "                dash_line)\n",
        "\n",
        "    mask,mask_s = generate_masks(cfg.train_data.mask_path,cfg.train_data.mask_shape)\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "    train_data = build_dataset(cfg.train_data,{\"mask\":mask})\n",
        "\n",
        "    if cfg.eval.flag:\n",
        "        test_data = build_dataset(cfg.test_data,{\"mask\":mask})\n",
        "    if args.distributed:\n",
        "        dist_sampler = DistributedSampler(train_data,shuffle=True)\n",
        "        train_data_loader = DataLoader(dataset=train_data, \n",
        "                                        batch_size=args.batch_size,\n",
        "                                        sampler=dist_sampler,\n",
        "                                        num_workers = cfg.data.workers_per_gpu)\n",
        "    else:\n",
        "        train_data_loader = DataLoader(dataset=train_data, \n",
        "                                        batch_size=args.batch_size,\n",
        "                                        shuffle=True,\n",
        "                                        num_workers = cfg.data.workers_per_gpu)\n",
        "    optimizer = build_optimizer(cfg.optimizer,{\"params\":model.parameters()})\n",
        "    # optimizer = StepLR(optimizer, step_size=30, gamma=0.8)\n",
        "    criterion = build_loss(cfg.loss)\n",
        "    criterion = criterion.to(args.device)\n",
        "    final_loss_sum = 0.\n",
        "    start_epoch = 0\n",
        "    tv_loss_sum = 0\n",
        "    if rank==0:\n",
        "        if cfg.checkpoints is not None:\n",
        "            logger.info(\"Load pre_train model...\")\n",
        "            resume_dict = torch.load(cfg.checkpoints)\n",
        "            if \"model_state_dict\" not in resume_dict.keys():\n",
        "                model_state_dict = resume_dict\n",
        "            else:\n",
        "                model_state_dict = resume_dict[\"model_state_dict\"]\n",
        "            load_checkpoints(model,model_state_dict)\n",
        "        else:            \n",
        "            logger.info(\"No pre_train model\")\n",
        "\n",
        "        if cfg.resume is not None:\n",
        "            logger.info(\"Load resume...\")\n",
        "            resume_dict = torch.load(cfg.resume)\n",
        "            start_epoch = resume_dict[\"epoch\"]\n",
        "            model_state_dict = resume_dict[\"model_state_dict\"]\n",
        "            load_checkpoints(model,model_state_dict)\n",
        "\n",
        "            optim_state_dict = resume_dict[\"optim_state_dict\"]\n",
        "            optimizer.load_state_dict(optim_state_dict)\n",
        "    if args.distributed:\n",
        "        model = DDP(model,device_ids=[local_rank],output_device=local_rank,find_unused_parameters=True)\n",
        "\n",
        "    iter_num = len(train_data_loader) \n",
        "    for epoch in range(start_epoch,cfg.runner.max_epochs):\n",
        "        epoch_loss = 0\n",
        "        model = model.train()\n",
        "        start_time = time.time()\n",
        "        for iteration, data in enumerate(train_data_loader):\n",
        "            gt, meas = data\n",
        "            gt = gt.float().to(args.device)\n",
        "            meas = meas.unsqueeze(1).float().to(args.device)\n",
        "            \n",
        "            meas_f = torch.cat((gt[:,0:1,:,:],meas,gt[:,-1:,:,:]),1)\n",
        "            \n",
        "            batch_size = meas.shape[0]\n",
        "\n",
        "            Phi = einops.repeat(mask,'cr h w->b cr h w',b=batch_size)\n",
        "            Phi_s = einops.repeat(mask_s,'h w->b 1 h w',b=batch_size)\n",
        "\n",
        "            Phi = torch.from_numpy(Phi).to(args.device)\n",
        "            Phi_s = torch.from_numpy(Phi_s).to(args.device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            model_out = model(meas_f,Phi,Phi_s)\n",
        "            \n",
        "            model_out_f = torch.cat((gt[:,0:1,:,:],model_out,gt[:,-1:,:,:]),1)\n",
        "            \n",
        "            final_loss = utils.weighted_L1loss(model_out_f, gt)\n",
        "            final_loss_sum += final_loss.item()\n",
        "\n",
        "            tv_loss = utils.gradx(model_out).abs().mean() + utils.grady(model_out).abs().mean()\n",
        "            tv_loss_sum += tv_loss.item()\n",
        "            loss = final_loss + 0.1*tv_loss\n",
        "            \n",
        "            if not isinstance(model_out,list):\n",
        "                model_out = [model_out]\n",
        "            \n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            if rank==0 and (iteration % cfg.log_config.interval) == 0:\n",
        "                lr = optimizer.state_dict()[\"param_groups\"][0][\"lr\"]\n",
        "                iter_len = len(str(iter_num))\n",
        "                logger.info(\"epoch: [{}][{:>{}}/{}], lr: {:.6f}, loss: {:.5f}.\".format(epoch,iteration,iter_len,iter_num,lr,loss.item()))\n",
        "                writer.add_scalar(\"loss\",loss.item(),epoch*len(train_data_loader) + iteration)\n",
        "            if rank==0 and (iteration % cfg.save_image_config.interval) == 0:\n",
        "                sing_out = model_out_f[0].detach().cpu().numpy()\n",
        "                sing_gt = gt[0].cpu().numpy()\n",
        "                sing_mask = mask\n",
        "                image_name = osp.join(train_image_save_dir,str(epoch)+\"_\"+str(iteration)+\".png\")\n",
        "                save_image(sing_out,sing_gt,sing_mask,image_name)\n",
        "        end_time = time.time()\n",
        "        if rank==0:\n",
        "            logger.info(\"epoch: {}, avg_loss: {:.5f}, time: {:.2f}s.\\n\".format(epoch,epoch_loss/(iteration+1),end_time-start_time))\n",
        "\n",
        "        if rank==0 and (epoch % cfg.checkpoint_config.interval) == 0:\n",
        "            if args.distributed:\n",
        "                save_model = model.module\n",
        "            else:\n",
        "                save_model = model\n",
        "            checkpoint_dict = {\n",
        "                \"epoch\": epoch, \n",
        "                \"model_state_dict\": save_model.state_dict(), \n",
        "                \"optim_state_dict\": optimizer.state_dict(), \n",
        "            }\n",
        "            torch.save(checkpoint_dict,osp.join(checkpoints_dir,\"epoch_\"+str(epoch)+\".pth\")) \n",
        "\n",
        "            if gdFlag is True:\n",
        "              torch.save(checkpoint_dict,osp.join(args.gdrivepath,\"epoch_\"+str(epoch)+\".pth\")) \n",
        "\n",
        "\n",
        "        if rank==0 and cfg.eval.flag and epoch % cfg.eval.interval==0:\n",
        "            if args.distributed:\n",
        "                psnr_dict,ssim_dict = eval_psnr_ssim(model.module,test_data,mask,mask_s,args)\n",
        "            else:\n",
        "                psnr_dict,ssim_dict = eval_psnr_ssim(model,test_data,mask,mask_s,args)\n",
        "\n",
        "            psnr_str = \", \".join([key+\": \"+\"{:.4f}\".format(psnr_dict[key]) for key in psnr_dict.keys()])\n",
        "            ssim_str = \", \".join([key+\": \"+\"{:.4f}\".format(ssim_dict[key]) for key in ssim_dict.keys()])\n",
        "            logger.info(\"Mean PSNR: \\n{}.\\n\".format(psnr_str))\n",
        "            logger.info(\"Mean SSIM: \\n{}.\\n\".format(ssim_str))\n",
        "        \n",
        "        "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "VP0QcgfHRmUL"
      },
      "source": [
        "## Transfer learning on Init model and train ST Transformer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8kOmhaXRyKs",
        "outputId": "7ed0613c-1c2f-4656-d456-81db59d71123"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "INFO:root:GPU info:\n",
            "--------------------------------------------------------------------------------\n",
            "CUDA available: True\n",
            "GPU numbers: 1\n",
            "GPU INFO: [{'GPU 0': 'Tesla T4'}]\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "2023-05-20 03:54:56,568 - <ipython-input-6-b68ba15ca55d> [line: 93] - GPU info:\n",
            "--------------------------------------------------------------------------------\n",
            "CUDA available: True\n",
            "GPU numbers: 1\n",
            "GPU INFO: [{'GPU 0': 'Tesla T4'}]\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "2023-05-20 03:54:56,568 - <ipython-input-6-b68ba15ca55d> [line: 93] - GPU info:\n",
            "--------------------------------------------------------------------------------\n",
            "CUDA available: True\n",
            "GPU numbers: 1\n",
            "GPU INFO: [{'GPU 0': 'Tesla T4'}]\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "INFO:root:cfg info:\n",
            "--------------------------------------------------------------------------------\n",
            "{\n",
            "    \"test_data\": {\n",
            "        \"type\": \"SixGraySimData\",\n",
            "        \"data_root\": \"test_datasets/simulation\",\n",
            "        \"mask_path\": \"test_datasets/mask/shutter_mask16.mat\",\n",
            "        \"mask_shape\": null\n",
            "    },\n",
            "    \"resize_h\": 256,\n",
            "    \"resize_w\": 256,\n",
            "    \"train_pipeline\": [\n",
            "        {\n",
            "            \"type\": \"RandomResize\"\n",
            "        },\n",
            "        {\n",
            "            \"type\": \"RandomCrop\",\n",
            "            \"crop_h\": 128,\n",
            "            \"crop_w\": 128,\n",
            "            \"random_size\": true\n",
            "        },\n",
            "        {\n",
            "            \"type\": \"Flip\",\n",
            "            \"direction\": \"horizontal\",\n",
            "            \"flip_ratio\": 0.5\n",
            "        },\n",
            "        {\n",
            "            \"type\": \"Flip\",\n",
            "            \"direction\": \"diagonal\",\n",
            "            \"flip_ratio\": 0.5\n",
            "        },\n",
            "        {\n",
            "            \"type\": \"Resize\",\n",
            "            \"resize_h\": 256,\n",
            "            \"resize_w\": 256\n",
            "        }\n",
            "    ],\n",
            "    \"gene_meas\": {\n",
            "        \"type\": \"GenerationGrayMeas\"\n",
            "    },\n",
            "    \"train_data\": {\n",
            "        \"type\": \"DavisData\",\n",
            "        \"data_root\": \"./dataset/DAVIS/JPEGImages/480p/\",\n",
            "        \"mask_path\": \"test_datasets/mask/shutter_mask16.mat\",\n",
            "        \"pipeline\": [\n",
            "            {\n",
            "                \"type\": \"RandomResize\"\n",
            "            },\n",
            "            {\n",
            "                \"type\": \"RandomCrop\",\n",
            "                \"crop_h\": 128,\n",
            "                \"crop_w\": 128,\n",
            "                \"random_size\": true\n",
            "            },\n",
            "            {\n",
            "                \"type\": \"Flip\",\n",
            "                \"direction\": \"horizontal\",\n",
            "                \"flip_ratio\": 0.5\n",
            "            },\n",
            "            {\n",
            "                \"type\": \"Flip\",\n",
            "                \"direction\": \"diagonal\",\n",
            "                \"flip_ratio\": 0.5\n",
            "            },\n",
            "            {\n",
            "                \"type\": \"Resize\",\n",
            "                \"resize_h\": 256,\n",
            "                \"resize_w\": 256\n",
            "            }\n",
            "        ],\n",
            "        \"gene_meas\": {\n",
            "            \"type\": \"GenerationGrayMeas\"\n",
            "        },\n",
            "        \"mask_shape\": [\n",
            "            256,\n",
            "            256,\n",
            "            16\n",
            "        ]\n",
            "    },\n",
            "    \"checkpoint_config\": {\n",
            "        \"interval\": 2\n",
            "    },\n",
            "    \"log_config\": {\n",
            "        \"interval\": 100\n",
            "    },\n",
            "    \"save_image_config\": {\n",
            "        \"interval\": 500\n",
            "    },\n",
            "    \"optimizer\": {\n",
            "        \"type\": \"Adam\",\n",
            "        \"lr\": 0.0001\n",
            "    },\n",
            "    \"loss\": {\n",
            "        \"type\": \"MSELoss\"\n",
            "    },\n",
            "    \"runner\": {\n",
            "        \"max_epochs\": 400,\n",
            "        \"max_epoch\": 400\n",
            "    },\n",
            "    \"checkpoints\": null,\n",
            "    \"resume\": null,\n",
            "    \"data\": {\n",
            "        \"samples_per_gpu\": 1,\n",
            "        \"workers_per_gpu\": 4\n",
            "    },\n",
            "    \"crop_h\": 128,\n",
            "    \"crop_w\": 128,\n",
            "    \"model\": {\n",
            "        \"type\": \"STFormer\",\n",
            "        \"color_channels\": 1,\n",
            "        \"units\": 2,\n",
            "        \"dim\": 32,\n",
            "        \"frames\": 16\n",
            "    },\n",
            "    \"eval\": {\n",
            "        \"flag\": true,\n",
            "        \"interval\": 1\n",
            "    }\n",
            "}\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "2023-05-20 03:54:56,576 - <ipython-input-6-b68ba15ca55d> [line: 97] - cfg info:\n",
            "--------------------------------------------------------------------------------\n",
            "{\n",
            "    \"test_data\": {\n",
            "        \"type\": \"SixGraySimData\",\n",
            "        \"data_root\": \"test_datasets/simulation\",\n",
            "        \"mask_path\": \"test_datasets/mask/shutter_mask16.mat\",\n",
            "        \"mask_shape\": null\n",
            "    },\n",
            "    \"resize_h\": 256,\n",
            "    \"resize_w\": 256,\n",
            "    \"train_pipeline\": [\n",
            "        {\n",
            "            \"type\": \"RandomResize\"\n",
            "        },\n",
            "        {\n",
            "            \"type\": \"RandomCrop\",\n",
            "            \"crop_h\": 128,\n",
            "            \"crop_w\": 128,\n",
            "            \"random_size\": true\n",
            "        },\n",
            "        {\n",
            "            \"type\": \"Flip\",\n",
            "            \"direction\": \"horizontal\",\n",
            "            \"flip_ratio\": 0.5\n",
            "        },\n",
            "        {\n",
            "            \"type\": \"Flip\",\n",
            "            \"direction\": \"diagonal\",\n",
            "            \"flip_ratio\": 0.5\n",
            "        },\n",
            "        {\n",
            "            \"type\": \"Resize\",\n",
            "            \"resize_h\": 256,\n",
            "            \"resize_w\": 256\n",
            "        }\n",
            "    ],\n",
            "    \"gene_meas\": {\n",
            "        \"type\": \"GenerationGrayMeas\"\n",
            "    },\n",
            "    \"train_data\": {\n",
            "        \"type\": \"DavisData\",\n",
            "        \"data_root\": \"./dataset/DAVIS/JPEGImages/480p/\",\n",
            "        \"mask_path\": \"test_datasets/mask/shutter_mask16.mat\",\n",
            "        \"pipeline\": [\n",
            "            {\n",
            "                \"type\": \"RandomResize\"\n",
            "            },\n",
            "            {\n",
            "                \"type\": \"RandomCrop\",\n",
            "                \"crop_h\": 128,\n",
            "                \"crop_w\": 128,\n",
            "                \"random_size\": true\n",
            "            },\n",
            "            {\n",
            "                \"type\": \"Flip\",\n",
            "                \"direction\": \"horizontal\",\n",
            "                \"flip_ratio\": 0.5\n",
            "            },\n",
            "            {\n",
            "                \"type\": \"Flip\",\n",
            "                \"direction\": \"diagonal\",\n",
            "                \"flip_ratio\": 0.5\n",
            "            },\n",
            "            {\n",
            "                \"type\": \"Resize\",\n",
            "                \"resize_h\": 256,\n",
            "                \"resize_w\": 256\n",
            "            }\n",
            "        ],\n",
            "        \"gene_meas\": {\n",
            "            \"type\": \"GenerationGrayMeas\"\n",
            "        },\n",
            "        \"mask_shape\": [\n",
            "            256,\n",
            "            256,\n",
            "            16\n",
            "        ]\n",
            "    },\n",
            "    \"checkpoint_config\": {\n",
            "        \"interval\": 2\n",
            "    },\n",
            "    \"log_config\": {\n",
            "        \"interval\": 100\n",
            "    },\n",
            "    \"save_image_config\": {\n",
            "        \"interval\": 500\n",
            "    },\n",
            "    \"optimizer\": {\n",
            "        \"type\": \"Adam\",\n",
            "        \"lr\": 0.0001\n",
            "    },\n",
            "    \"loss\": {\n",
            "        \"type\": \"MSELoss\"\n",
            "    },\n",
            "    \"runner\": {\n",
            "        \"max_epochs\": 400,\n",
            "        \"max_epoch\": 400\n",
            "    },\n",
            "    \"checkpoints\": null,\n",
            "    \"resume\": null,\n",
            "    \"data\": {\n",
            "        \"samples_per_gpu\": 1,\n",
            "        \"workers_per_gpu\": 4\n",
            "    },\n",
            "    \"crop_h\": 128,\n",
            "    \"crop_w\": 128,\n",
            "    \"model\": {\n",
            "        \"type\": \"STFormer\",\n",
            "        \"color_channels\": 1,\n",
            "        \"units\": 2,\n",
            "        \"dim\": 32,\n",
            "        \"frames\": 16\n",
            "    },\n",
            "    \"eval\": {\n",
            "        \"flag\": true,\n",
            "        \"interval\": 1\n",
            "    }\n",
            "}\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "2023-05-20 03:54:56,576 - <ipython-input-6-b68ba15ca55d> [line: 97] - cfg info:\n",
            "--------------------------------------------------------------------------------\n",
            "{\n",
            "    \"test_data\": {\n",
            "        \"type\": \"SixGraySimData\",\n",
            "        \"data_root\": \"test_datasets/simulation\",\n",
            "        \"mask_path\": \"test_datasets/mask/shutter_mask16.mat\",\n",
            "        \"mask_shape\": null\n",
            "    },\n",
            "    \"resize_h\": 256,\n",
            "    \"resize_w\": 256,\n",
            "    \"train_pipeline\": [\n",
            "        {\n",
            "            \"type\": \"RandomResize\"\n",
            "        },\n",
            "        {\n",
            "            \"type\": \"RandomCrop\",\n",
            "            \"crop_h\": 128,\n",
            "            \"crop_w\": 128,\n",
            "            \"random_size\": true\n",
            "        },\n",
            "        {\n",
            "            \"type\": \"Flip\",\n",
            "            \"direction\": \"horizontal\",\n",
            "            \"flip_ratio\": 0.5\n",
            "        },\n",
            "        {\n",
            "            \"type\": \"Flip\",\n",
            "            \"direction\": \"diagonal\",\n",
            "            \"flip_ratio\": 0.5\n",
            "        },\n",
            "        {\n",
            "            \"type\": \"Resize\",\n",
            "            \"resize_h\": 256,\n",
            "            \"resize_w\": 256\n",
            "        }\n",
            "    ],\n",
            "    \"gene_meas\": {\n",
            "        \"type\": \"GenerationGrayMeas\"\n",
            "    },\n",
            "    \"train_data\": {\n",
            "        \"type\": \"DavisData\",\n",
            "        \"data_root\": \"./dataset/DAVIS/JPEGImages/480p/\",\n",
            "        \"mask_path\": \"test_datasets/mask/shutter_mask16.mat\",\n",
            "        \"pipeline\": [\n",
            "            {\n",
            "                \"type\": \"RandomResize\"\n",
            "            },\n",
            "            {\n",
            "                \"type\": \"RandomCrop\",\n",
            "                \"crop_h\": 128,\n",
            "                \"crop_w\": 128,\n",
            "                \"random_size\": true\n",
            "            },\n",
            "            {\n",
            "                \"type\": \"Flip\",\n",
            "                \"direction\": \"horizontal\",\n",
            "                \"flip_ratio\": 0.5\n",
            "            },\n",
            "            {\n",
            "                \"type\": \"Flip\",\n",
            "                \"direction\": \"diagonal\",\n",
            "                \"flip_ratio\": 0.5\n",
            "            },\n",
            "            {\n",
            "                \"type\": \"Resize\",\n",
            "                \"resize_h\": 256,\n",
            "                \"resize_w\": 256\n",
            "            }\n",
            "        ],\n",
            "        \"gene_meas\": {\n",
            "            \"type\": \"GenerationGrayMeas\"\n",
            "        },\n",
            "        \"mask_shape\": [\n",
            "            256,\n",
            "            256,\n",
            "            16\n",
            "        ]\n",
            "    },\n",
            "    \"checkpoint_config\": {\n",
            "        \"interval\": 2\n",
            "    },\n",
            "    \"log_config\": {\n",
            "        \"interval\": 100\n",
            "    },\n",
            "    \"save_image_config\": {\n",
            "        \"interval\": 500\n",
            "    },\n",
            "    \"optimizer\": {\n",
            "        \"type\": \"Adam\",\n",
            "        \"lr\": 0.0001\n",
            "    },\n",
            "    \"loss\": {\n",
            "        \"type\": \"MSELoss\"\n",
            "    },\n",
            "    \"runner\": {\n",
            "        \"max_epochs\": 400,\n",
            "        \"max_epoch\": 400\n",
            "    },\n",
            "    \"checkpoints\": null,\n",
            "    \"resume\": null,\n",
            "    \"data\": {\n",
            "        \"samples_per_gpu\": 1,\n",
            "        \"workers_per_gpu\": 4\n",
            "    },\n",
            "    \"crop_h\": 128,\n",
            "    \"crop_w\": 128,\n",
            "    \"model\": {\n",
            "        \"type\": \"STFormer\",\n",
            "        \"color_channels\": 1,\n",
            "        \"units\": 2,\n",
            "        \"dim\": 32,\n",
            "        \"frames\": 16\n",
            "    },\n",
            "    \"eval\": {\n",
            "        \"flag\": true,\n",
            "        \"interval\": 1\n",
            "    }\n",
            "}\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "INFO:root:Model info:\n",
            "--------------------------------------------------------------------------------\n",
            "STFormer(\n",
            "  (token_gen): Sequential(\n",
            "    (0): Conv3d(1, 32, kernel_size=(5, 5, 5), stride=(1, 1, 1), padding=(2, 2, 2))\n",
            "    (1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "    (2): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (3): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "    (4): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "    (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "    (6): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))\n",
            "    (7): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "    (8): Conv3d(128, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (9): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "  )\n",
            "  (conv2): Sequential(\n",
            "    (0): ConvTranspose3d(128, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), output_padding=(0, 1, 1))\n",
            "    (1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "    (2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "    (3): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "    (4): Conv3d(64, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "    (6): Conv3d(32, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "  )\n",
            "  (layers): ModuleList(\n",
            "    (0-1): 2 x STFormerLayer(\n",
            "      (blocks): ModuleList(\n",
            "        (0-1): 2 x STFormerBlock(\n",
            "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "          (attn): SpaceAttention(\n",
            "            (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
            "            (proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "            (softmax): Softmax(dim=-1)\n",
            "          )\n",
            "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "          (ff): GRFFNet(\n",
            "            (part1): Sequential(\n",
            "              (0): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "              (1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "              (2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "            )\n",
            "            (part2): Sequential(\n",
            "              (0): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "              (1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "              (2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "            )\n",
            "          )\n",
            "          (time_attn): TimeAttention(\n",
            "            (qkv): Linear(in_features=128, out_features=192, bias=True)\n",
            "            (proj): Linear(in_features=64, out_features=128, bias=True)\n",
            "            (softmax): Softmax(dim=-1)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (FeatureExtractor): Sequential(\n",
            "    (0): Conv2d(1, 16, kernel_size=(15, 15), stride=(1, 1), padding=(7, 7))\n",
            "    (1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "    (2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (3): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "    (4): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "  )\n",
            ")\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "2023-05-20 03:54:56,585 - <ipython-input-6-b68ba15ca55d> [line: 101] - Model info:\n",
            "--------------------------------------------------------------------------------\n",
            "STFormer(\n",
            "  (token_gen): Sequential(\n",
            "    (0): Conv3d(1, 32, kernel_size=(5, 5, 5), stride=(1, 1, 1), padding=(2, 2, 2))\n",
            "    (1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "    (2): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (3): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "    (4): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "    (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "    (6): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))\n",
            "    (7): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "    (8): Conv3d(128, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (9): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "  )\n",
            "  (conv2): Sequential(\n",
            "    (0): ConvTranspose3d(128, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), output_padding=(0, 1, 1))\n",
            "    (1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "    (2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "    (3): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "    (4): Conv3d(64, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "    (6): Conv3d(32, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "  )\n",
            "  (layers): ModuleList(\n",
            "    (0-1): 2 x STFormerLayer(\n",
            "      (blocks): ModuleList(\n",
            "        (0-1): 2 x STFormerBlock(\n",
            "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "          (attn): SpaceAttention(\n",
            "            (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
            "            (proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "            (softmax): Softmax(dim=-1)\n",
            "          )\n",
            "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "          (ff): GRFFNet(\n",
            "            (part1): Sequential(\n",
            "              (0): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "              (1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "              (2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "            )\n",
            "            (part2): Sequential(\n",
            "              (0): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "              (1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "              (2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "            )\n",
            "          )\n",
            "          (time_attn): TimeAttention(\n",
            "            (qkv): Linear(in_features=128, out_features=192, bias=True)\n",
            "            (proj): Linear(in_features=64, out_features=128, bias=True)\n",
            "            (softmax): Softmax(dim=-1)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (FeatureExtractor): Sequential(\n",
            "    (0): Conv2d(1, 16, kernel_size=(15, 15), stride=(1, 1), padding=(7, 7))\n",
            "    (1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "    (2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (3): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "    (4): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "  )\n",
            ")\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "2023-05-20 03:54:56,585 - <ipython-input-6-b68ba15ca55d> [line: 101] - Model info:\n",
            "--------------------------------------------------------------------------------\n",
            "STFormer(\n",
            "  (token_gen): Sequential(\n",
            "    (0): Conv3d(1, 32, kernel_size=(5, 5, 5), stride=(1, 1, 1), padding=(2, 2, 2))\n",
            "    (1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "    (2): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (3): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "    (4): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "    (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "    (6): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))\n",
            "    (7): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "    (8): Conv3d(128, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (9): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "  )\n",
            "  (conv2): Sequential(\n",
            "    (0): ConvTranspose3d(128, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), output_padding=(0, 1, 1))\n",
            "    (1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "    (2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "    (3): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "    (4): Conv3d(64, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "    (6): Conv3d(32, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "  )\n",
            "  (layers): ModuleList(\n",
            "    (0-1): 2 x STFormerLayer(\n",
            "      (blocks): ModuleList(\n",
            "        (0-1): 2 x STFormerBlock(\n",
            "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "          (attn): SpaceAttention(\n",
            "            (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
            "            (proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "            (softmax): Softmax(dim=-1)\n",
            "          )\n",
            "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "          (ff): GRFFNet(\n",
            "            (part1): Sequential(\n",
            "              (0): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "              (1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "              (2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "            )\n",
            "            (part2): Sequential(\n",
            "              (0): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "              (1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "              (2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "            )\n",
            "          )\n",
            "          (time_attn): TimeAttention(\n",
            "            (qkv): Linear(in_features=128, out_features=192, bias=True)\n",
            "            (proj): Linear(in_features=64, out_features=128, bias=True)\n",
            "            (softmax): Softmax(dim=-1)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (FeatureExtractor): Sequential(\n",
            "    (0): Conv2d(1, 16, kernel_size=(15, 15), stride=(1, 1), padding=(7, 7))\n",
            "    (1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "    (2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (3): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "    (4): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "  )\n",
            ")\n",
            "--------------------------------------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Init Model checkpoint loaded\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "INFO:root:No pre_train model\n",
            "2023-05-20 03:54:56,827 - <ipython-input-6-b68ba15ca55d> [line: 137] - No pre_train model\n",
            "2023-05-20 03:54:56,827 - <ipython-input-6-b68ba15ca55d> [line: 137] - No pre_train model\n",
            "INFO:root:epoch: [0][    0/11481], lr: 0.000100, loss: 0.55150.\n",
            "2023-05-20 03:55:00,569 - <ipython-input-6-b68ba15ca55d> [line: 190] - epoch: [0][    0/11481], lr: 0.000100, loss: 0.55150.\n",
            "2023-05-20 03:55:00,569 - <ipython-input-6-b68ba15ca55d> [line: 190] - epoch: [0][    0/11481], lr: 0.000100, loss: 0.55150.\n"
          ]
        }
      ],
      "source": [
        "parser = argparse.ArgumentParser() \n",
        "args = parser.parse_args(args=[])\n",
        "args.config = './configs/STFormer/stformer_base.py'\n",
        "args.work_dir = './train_results/3meas_coarse_nm/'\n",
        "args.dataset_path = './dataset/DAVIS/JPEGImages/480p/'\n",
        "args.initModelPath = './train_results/3meas_coarse_nm/checkpoints/epoch_0.pth'\n",
        "args.device = \"cuda\"\n",
        "args.resolution = [256,256]\n",
        "args.frames = 16\n",
        "args.dataset_crop = [128,128]\n",
        "args.distributed = False\n",
        "args.resume = None\n",
        "args.Epochs = 400\n",
        "args.batch_size = 1\n",
        "args.learning_rate = 0.0001\n",
        "args.saveImageEach = 500\n",
        "args.saveModelEach = 2\n",
        "args.checkpoints = None\n",
        "args.local_rank = -1\n",
        "args.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "if os.path.exists('/content/gdrive'):\n",
        "    print(\"GDrive Mounted, saving results on MyDrive/PulsedIlluminationRepository/results/\")\n",
        "    args.gdrivepath = \"/content/gdrive/MyDrive/PulsedIlluminationRepository/results/\"\n",
        "    if os.path.exists(args.gdrivepath):\n",
        "      os.makedirs(args.gdrivepath)\n",
        "      gdFlag = True\n",
        "else:\n",
        "  gdFlag = False  \n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    cfg = Config.fromfile(args.config)\n",
        "    cfg.resize_h,cfg.resize_w = args.resolution\n",
        "    cfg.crop_h,cfg.crop_w = args.dataset_crop\n",
        "    \n",
        "    cfg.train_pipeline[4]['resize_h'],cfg.train_pipeline[4]['resize_w'] = args.resolution\n",
        "    cfg.train_pipeline[1]['crop_h'],cfg.train_pipeline[1]['crop_w'] = args.dataset_crop\n",
        "    cfg.train_data.mask_shape = (args.resolution[0],args.resolution[1],args.frames)\n",
        "    \n",
        "\n",
        "    cfg.save_image_config['interval'] = args.saveImageEach\n",
        "    cfg.runner['max_epoch'] = args.Epochs\n",
        "    cfg.train_data['data_root'] = args.dataset_path\n",
        "    cfg.checkpoints = args.checkpoints\n",
        "    cfg.checkpoint_config['interval'] = args.saveModelEach\n",
        "    cfg.optimizer['lr'] = args.learning_rate\n",
        "    cfg.data['samples_per_gpu'] = args.batch_size\n",
        "    if args.work_dir is None:\n",
        "        args.work_dir = osp.join('./work_dirs',osp.splitext(osp.basename(args.config))[0])\n",
        "\n",
        "    if args.resume is not None:\n",
        "        cfg.resume = args.resume\n",
        "\n",
        "    log_dir = osp.join(args.work_dir,\"log\")\n",
        "    show_dir = osp.join(args.work_dir,\"show\")\n",
        "    train_image_save_dir = osp.join(args.work_dir,\"train_images\")\n",
        "    checkpoints_dir = osp.join(args.work_dir,\"checkpoints\")\n",
        "\n",
        "    if not osp.exists(log_dir):\n",
        "        os.makedirs(log_dir)\n",
        "    if not osp.exists(show_dir):\n",
        "        os.makedirs(show_dir)\n",
        "    if not osp.exists(train_image_save_dir):\n",
        "        os.makedirs(train_image_save_dir)\n",
        "    if not osp.exists(checkpoints_dir):\n",
        "        os.makedirs(checkpoints_dir)\n",
        "\n",
        "    logger = Logger(log_dir)\n",
        "    writer = SummaryWriter(log_dir = show_dir)\n",
        "\n",
        "    rank = 0 \n",
        "    if args.distributed:\n",
        "        local_rank = int(args.local_rank)\n",
        "        dist.init_process_group(backend=\"nccl\")\n",
        "        rank = dist.get_rank()\n",
        "\n",
        "    dash_line = '-' * 80 + '\\n'\n",
        "    device_info = get_device_info()\n",
        "    env_info = '\\n'.join(['{}: {}'.format(k,v) for k, v in device_info.items()])\n",
        "    \n",
        "    device = args.device\n",
        "    model = build_model(cfg.model).to(device)\n",
        "    \n",
        "    DeModel = UNet(in_channel=16, out_channel=14, instance_norm=False).cuda()\n",
        "    \n",
        "    if os.path.exists(args.initModelPath):\n",
        "        resume_dict = torch.load(args.initModelPath)\n",
        "        model_state_dict = resume_dict[\"model_state_dict\"]\n",
        "        load_checkpoints(DeModel,model_state_dict)\n",
        "        print(\"Init Model checkpoint loaded\")\n",
        "    else:\n",
        "        # File does not exist\n",
        "        print(\"Init Model checkpoint not found. Starting from scrach\")\n",
        "\n",
        "\n",
        "    #for name, para in DeModel.named_parameters(): #Freeze Unet\n",
        "    #   para.requires_grad = False\n",
        "    \n",
        "    if rank==0:\n",
        "        logger.info('GPU info:\\n' \n",
        "                + dash_line + \n",
        "                env_info + '\\n' +\n",
        "                dash_line)\n",
        "        logger.info('cfg info:\\n'\n",
        "                + dash_line + \n",
        "                json.dumps(cfg, indent=4)+'\\n'+\n",
        "                dash_line) \n",
        "        logger.info('Model info:\\n'\n",
        "                + dash_line + \n",
        "                str(model)+'\\n'+\n",
        "                dash_line)\n",
        "\n",
        "    mask,mask_s = generate_masks(cfg.train_data.mask_path,cfg.train_data.mask_shape)\n",
        "    train_data = build_dataset(cfg.train_data,{\"mask\":mask})\n",
        "    if cfg.eval.flag:\n",
        "        test_data = build_dataset(cfg.test_data,{\"mask\":mask})\n",
        "    if args.distributed:\n",
        "        dist_sampler = DistributedSampler(train_data,shuffle=True)\n",
        "        train_data_loader = DataLoader(dataset=train_data, \n",
        "                                        batch_size=cfg.data.samples_per_gpu,\n",
        "                                        sampler=dist_sampler,\n",
        "                                        num_workers = cfg.data.workers_per_gpu)\n",
        "    else:\n",
        "        train_data_loader = DataLoader(dataset=train_data, \n",
        "                                        batch_size=cfg.data.samples_per_gpu,\n",
        "                                        shuffle=True,\n",
        "                                        num_workers = cfg.data.workers_per_gpu)\n",
        "    optimizer = build_optimizer(cfg.optimizer,{\"params\":model.parameters()})\n",
        "    \n",
        "    criterion = build_loss(cfg.loss)\n",
        "    criterion = criterion.to(args.device)\n",
        "    \n",
        "    start_epoch = 0\n",
        "    if rank==0:\n",
        "        if cfg.checkpoints is not None:\n",
        "            logger.info(\"Load pre_train model...\")\n",
        "            resume_dict = torch.load(cfg.checkpoints)\n",
        "            if \"model_state_dict\" not in resume_dict.keys():\n",
        "                model_state_dict = resume_dict\n",
        "            else:\n",
        "                model_state_dict = resume_dict[\"model_state_dict\"]\n",
        "            load_checkpoints(model,model_state_dict)\n",
        "        else:            \n",
        "            logger.info(\"No pre_train model\")\n",
        "\n",
        "        if cfg.resume is not None:\n",
        "            logger.info(\"Load resume...\")\n",
        "            resume_dict = torch.load(cfg.resume)\n",
        "            start_epoch = resume_dict[\"epoch\"]\n",
        "            model_state_dict = resume_dict[\"model_state_dict\"]\n",
        "            load_checkpoints(model,model_state_dict)\n",
        "            Demodel_state_dict = resume_dict[\"Demodel_state_dict\"]\n",
        "            load_checkpoints(DeModel,Demodel_state_dict)\n",
        "\n",
        "            optim_state_dict = resume_dict[\"optim_state_dict\"]\n",
        "            optimizer.load_state_dict(optim_state_dict)\n",
        "    if args.distributed:\n",
        "        model = DDP(model,device_ids=[local_rank],output_device=local_rank,find_unused_parameters=True)\n",
        "    \n",
        "    iter_num = len(train_data_loader) \n",
        "    for epoch in range(start_epoch,cfg.runner.max_epochs):\n",
        "        epoch_loss = 0\n",
        "        model = model.train()\n",
        "        start_time = time.time()\n",
        "        for iteration, data in enumerate(train_data_loader):\n",
        "            gt, meas = data\n",
        "            gt = gt.float().to(args.device)\n",
        "            meas = meas.unsqueeze(1).float().to(args.device)\n",
        "            batch_size = meas.shape[0]\n",
        "\n",
        "            Phi = einops.repeat(mask,'cr h w->b cr h w',b=batch_size)\n",
        "            Phi_s = einops.repeat(mask_s,'h w->b 1 h w',b=batch_size)\n",
        "\n",
        "            Phi = torch.from_numpy(Phi).to(args.device)\n",
        "            Phi_s = torch.from_numpy(Phi_s).to(args.device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            meas_f = torch.cat((gt[:,0:1,:,:],meas,gt[:,-1:,:,:]),1)\n",
        "            \n",
        "            de_meas = DeModel(meas_f,Phi,Phi_s)\n",
        "            model_out = model(de_meas,Phi,Phi_s)\n",
        "            model_out_f = torch.cat((gt[:,0:1,:,:],model_out[0],gt[:,-1:,:,:]),1)\n",
        "            \n",
        "\n",
        "\n",
        "\n",
        "            if not isinstance(model_out,list):\n",
        "                model_out = [model_out_f]\n",
        "            loss = torch.sqrt(criterion(model_out_f, gt))\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            if rank==0 and (iteration % cfg.log_config.interval) == 0:\n",
        "                lr = optimizer.state_dict()[\"param_groups\"][0][\"lr\"]\n",
        "                iter_len = len(str(iter_num))\n",
        "                logger.info(\"epoch: [{}][{:>{}}/{}], lr: {:.6f}, loss: {:.5f}.\".format(epoch,iteration,iter_len,iter_num,lr,loss.item()))\n",
        "                writer.add_scalar(\"loss\",loss.item(),epoch*len(train_data_loader) + iteration)\n",
        "            if rank==0 and (iteration % cfg.save_image_config.interval) == 0:\n",
        "                sing_out = model_out_f[0].detach().cpu().numpy()\n",
        "                sing_gt = gt[0].cpu().numpy()\n",
        "                #print(sing_gt.shape)\n",
        "                #print(mask.shape)\n",
        "                sing_mask = mask\n",
        "                image_name = osp.join(train_image_save_dir,str(epoch)+\"_\"+str(iteration)+\".png\")\n",
        "                save_image(sing_out,sing_gt,sing_mask,image_name)\n",
        "        end_time = time.time()\n",
        "        if rank==0:\n",
        "            logger.info(\"epoch: {}, avg_loss: {:.5f}, time: {:.2f}s.\\n\".format(epoch,epoch_loss/(iteration+1),end_time-start_time))\n",
        "\n",
        "        if rank==0 and (epoch % cfg.checkpoint_config.interval) == 0:\n",
        "            if args.distributed:\n",
        "                save_model = model.module\n",
        "                save_De = DeModel.module\n",
        "            else:\n",
        "                save_model = model\n",
        "                save_De = DeModel\n",
        "            checkpoint_dict = {\n",
        "                \"epoch\": epoch, \n",
        "                \"model_state_dict\": save_model.state_dict(), \n",
        "                \"Demodel_state_dict\": save_De.state_dict(),\n",
        "                \"optim_state_dict\": optimizer.state_dict(), \n",
        "            }\n",
        "            torch.save(checkpoint_dict,osp.join(checkpoints_dir,\"epoch_\"+str(epoch)+\".pth\")) \n",
        "\n",
        "            if gdFlag is True:\n",
        "              torch.save(checkpoint_dict,osp.join(args.gdrivepath,\"epoch_\"+str(epoch)+\".pth\")) \n",
        "\n",
        "        if rank==0 and cfg.eval.flag and epoch % cfg.eval.interval==0:\n",
        "            if args.distributed:\n",
        "                psnr_dict,ssim_dict = eval_psnr_ssim(model.module,test_data,mask,mask_s,args)\n",
        "            else:\n",
        "                psnr_dict,ssim_dict = eval_psnr_ssim(model,DeModel,test_data,mask,mask_s,args)\n",
        "                #psnr_dict,ssim_dict = 0,0\n",
        "\n",
        "    \n",
        "            psnr_str = \", \".join([key+\": \"+\"{:.4f}\".format(psnr_dict[key]) for key in psnr_dict.keys()])           \n",
        "            ssim_str = \", \".join([key+\": \"+\"{:.4f}\".format(ssim_dict[key]) for key in ssim_dict.keys()])\n",
        "            logger.info(\"Mean PSNR: \\n{}.\\n\".format(psnr_str))\n",
        "            logger.info(\"Mean SSIM: \\n{}.\\n\".format(ssim_str))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyOY5Df97OVCGf2ah0vDB3Jq",
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
